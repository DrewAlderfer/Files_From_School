import matplotlib.pyplot as pltfrom sklearn.linear_model import *from sklearn.linear_model import Ridgefrom sklearn.preprocessing import MinMaxScaler, OneHotEncoderimport sysimport numpy as npfrom sklearn.preprocessing import StandardScalerfrom sklearn.impute import SimpleImputerfrom sklearn import svmfrom sklearn.neighbors import KNeighborsClassifierfrom ride import Ridefrom sklearn.datasets import make_blobsfrom tqdm.autonotebook import tqdmfrom sklearn.model_selection import train_test_split, cross_val_scorefrom sklearn.preprocessing import LabelEncoderfrom sklearn.linear_model import LinearRegressionfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_reportfrom sklearn.linear_model import Lassofrom sklearn import treefrom sklearn.linear_model import LogisticRegressionimport itertoolsfrom sklearn.model_selection import train_test_splitfrom sklearn.linear_model import LinearRegression, Lassofrom sklearn.metrics import confusion_matrixfrom scipy import statsfrom xgboost import XGBClassifierfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifierimport randomfrom sklearn.metrics import plot_confusion_matrixfrom sklearn.metrics import mean_squared_error as _msefrom sklearn.metrics import roc_curve, aucfrom sklearn.metrics import mean_absolute_error, mean_squared_errorfrom sklearn.model_selection import cross_val_scoreimport warningsfrom scipy.special import combfrom sklearn.metrics import confusion_matrix, plot_confusion_matrixfrom sklearn.datasets import load_irisfrom sklearn.svm import SVCfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_reportfrom sklearn.metrics import accuracy_score, roc_curve, aucimport pandas as pdfrom itertools import combinationsfrom sklearn.datasets import make_moonsfrom imblearn.over_sampling import SMOTE, ADASYNimport csvfrom sklearn.metrics import precision_score, recall_score, accuracy_score, f1_scorefrom sklearn.metrics import accuracy_scoreimport scipy.stats as statsimport ridefrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_scorefrom sklearn.preprocessing import StandardScaler, PolynomialFeaturesfrom sklearn.metrics import mean_squared_errorfrom sklearn.feature_selection import RFEfrom math import logfrom shopping_cart import ShoppingCartfrom sklearn.preprocessing import FunctionTransformer, OneHotEncoderfrom sklearn.ensemble import BaggingClassifier, RandomForestClassifierimport cvxpy as cpfrom sklearn.tree import DecisionTreeRegressorimport matplotlib as mplfrom school import Schoolfrom scipy.spatial.distance import euclideanfrom matplotlib.patches import Polygonfrom sklearn.metrics import r2_score, mean_squared_errorimport statsmodels as smfrom pylab import rcParamsfrom sklearn.preprocessing import OneHotEncoderfrom tabulate import tabulateimport timeitfrom sklearn.model_selection import GridSearchCVfrom sklearn.tree import DecisionTreeClassifierfrom sklearn.preprocessing import PolynomialFeaturesimport seaborn as snsimport statsmodels.api as smfrom sklearn.preprocessing import MinMaxScalerfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifierfrom driver import Driver#----------------------------------------------------------------------------------------------------# comb as comb#----------------------------------------------------------------------------------------------------comb(a + b, a)y.append(comb(a + b, a))#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# matplotlib.pyplot as plt#----------------------------------------------------------------------------------------------------plt.plot(min_samples_splits, r2_results, 'b', label='R2')plt.plot(x_values, y_values, label='3x^2 - 11')plt.subplots(figsize=(10, 6))plt.plot(train_fpr, train_tpr, color='blue', lw=lw, label='Custom Model Train ROC curve')plt.legend(loc='upper left')plt.xticks([i / 20.0 for i in range(21)])plt.plot(train_fpr, train_tpr, color='gold', lw=lw, label='Scikit learn Model 1 Train ROC curve')plt.title('Model vs data for test set')plt.plot(train_fpr, train_tpr, color='darkorange', lw=lw, label='ROC curve')plt.xlabel(col)plt.scatter(1.1124498053361267, rss(1.1124498053361267), c='red')plt.subplot(3, 3, k + 1)plt.scatter(list(range(10, 95)), testing_f1, label='testing_f1')plt.plot(y_test, y_test, label='Actual data')plt.figure(figsize=(8, 8))plt.plot(range_stds, train_accs, label='Train Accuracy')plt.yticks([i / 20.0 for i in range(21)])plt.subplot(221)plt.savefig('./decision_tree.png')plt.title('Two Blobs with Mild Overlap')plt.scatter(X_4[:, 0], X_4[:, 1], c=y_4, s=25)plt.style.use('seaborn')plt.plot(max_depths, train_results, 'b', label='Train AUC')plt.title('Gross Domestic Sales vs. Budget', fontsize=18)plt.figure(figsize=(20, 5))plt.ylabel('RMSE')plt.ylabel('Feature')plt.scatter(y_test, lm_test_predictions, label='Model')plt.plot(min_samples_leafs, test_results, 'r', label='Test AUC')plt.ylabel('Classifier Accuracy')plt.scatter(y_train, poly_train_predictions, label='Model')plt.scatter(X_2[:, 0], X_2[:, 1], c=y_2, s=25)plt.plot(x, y)plt.title('SVC, C=0.1')plt.title('d= %r, gam= %r, r = %r , score = %r' % (d, gamma, r, round(clf.score(X_test, y_test), 2)))plt.axvline(x=0, color='lightgrey')plt.title('Model vs data for training set')plt.subplot(1, 3, i + 1)plt.title('RSS Loss Function for Various Values of m, with minimum marked')plt.plot([d1_min, d1_max], [sup_up_at_mind1, sup_up_at_maxd1], '-.', color='blue')plt.title('Two Moons with Substantial Overlap')plt.plot(fpr, tpr, color=colors[n], lw=lw, label='ROC curve Normalization Weight: {}'.format(names[n]))plt.plot(x, pdf)plt.subplot(122)plt.plot(data[col], target, 'o')plt.plot(x_values, derivative_values, color='darkorange', label="f '(x)")plt.subplots(figsize=(12, 5))plt.plot(y_pred, linestyle='-', marker='o', label='predictions')plt.figure(figsize=(12, 6))plt.gca()plt.plot(max_depths, r2_results, 'b', label='R2')plt.legend(bbox_to_anchor=(1, 1))plt.title('Conditional Probability of Resting Blood Pressure ~145 for Those With Heart Disease')plt.figure(figsize=(7, 6))plt.plot(y_test, linestyle='-', marker='o', label='actual values')plt.scatter(X1, X2, c=y_train, edgecolors='gray')plt.plot(test_fpr, test_tpr, color='darkorange', lw=lw, label='Custom Model Test ROC curve')plt.plot(x_values, function_values, label='f (x)')plt.xlabel('Feature importance')plt.figure(figsize=(11, 11))plt.figure(figsize=(8, 5))plt.scatter(list(range(10, 95)), training_f1, label='training_f1')plt.plot(min_samples_splits, mse_results, 'r', label='RMSE')plt.plot(min_samples_splits, test_results, 'r', label='Test AUC')plt.show()plt.title('Two interleaving half circles')plt.title('d= %r, gam= %r, r = %r , score = %r' % (d, gamma, r, round(clf.score(X_3, y_3), 2)))(fig, ax) = plt.subplots(figsize=(10, 7))plt.scatter(list(range(10, 95)), training_recall, label='training_recall')plt.title('NuSVC, nu=0.5')plt.plot((145, 145), (0, stats.norm.pdf(145, loc=aggs['mean'], scale=aggs['std'])), linestyle='dotted')plt.plot(test_fpr, test_tpr, color='darkorange', lw=lw, label='ROC curve')plt.plot(max_depths, mse_results, 'r', label='RMSE')plt.xlabel('max features')plt.xlabel('Tree Depth')plt.plot([d1_min, d1_max], [sup_dn_at_mind1, sup_dn_at_maxd1], '-.', color='blue')plt.plot(max_depths, test_results, 'r', label='Test AUC')plt.plot(y_train, y_train, label='Actual data')plt.scatter(X_3[:, 0], X_3[:, 1], c=y_3, s=25)plt.title('Combination sample space of a 25 observation sample compared to various second sample sizes')plt.subplot(4, 2, k + 1)plot_confusion_matrix(logreg, X_test, y_test, cmap=plt.cm.Blues)plt.plot(min_samples_leafs, train_results, 'b', label='Train AUC')plt.legend(loc='lower right')plt.figure(figsize=(20, 10))plt.plot(tan_line['x_dev'], tan_line['tan'], color='yellow', label=tan_line['lab'])plt.legend(loc=(1.01, 0.85))plt.title('Receiver operating characteristic (ROC) Curve for Training Set')plt.style.use('ggplot')plt.scatter(y_train, lm_train_predictions, label='Model')plt.plot(x_values, y_values, label='4x + 15')plt.scatter(X1, X2, c=y_test, edgecolors='gray')plt.xlim([0.0, 1.0])plt.plot(test_fpr, test_tpr, color='yellow', lw=lw, label='Scikit learn Model 1 Test ROC curve')plt.ylim([np.floor(np.min([x[:, 1], y[:, 1]])), np.ceil(np.max([x[:, 1], y[:, 1]]))])plt.plot(test_fpr, test_tpr, color='purple', lw=lw, label='Scikit learn Model 2 with intercept Test ROC curve')plt.scatter(list(range(10, 95)), testing_recall, label='testing_recall')plt.plot(train_fpr, train_tpr, color='blue', lw=lw, label='Train ROC curve')plt.plot(x_values, y_values, label='3x^2 + 11')plt.title('SVC, C=1')plt.vlines(x=x_value + delta_x, ymin=y_val, ymax=y_val_max, color='darkorange', label=vline_lab)plt.ylabel('R-squared')plt.title('RSS Loss Function for Various Values of m')plt.xlabel('Size of second sample')plt.title('Receiver operating characteristic (ROC) Curve for Test Set')plt.title(col)plt.scatter(X[:, 0], X[:, 1], c=y, s=25)plt.figure(figsize=(12, 12))plt.title('Four Blobs')plt.title(' gam= %r, r = %r , score = %r' % (gamma, r, round(clf.score(X_3, y_3), 2)))plt.axhline(y=0, color='lightgrey')plt.scatter(X_4[:, 0], X_4[:, 1], c=y_4, edgecolors='gray')plt.plot(x_values, derivative_values, color='darkorange', label="f '(x) = 6x")plt.scatter(X_11, X_12, c=y_1)plt.scatter(X[:, 0], X[:, 1], c=labels, s=25)plt.scatter(x, 1.331 * x, label='Median Ratio Model')plt.figure(figsize=(12, 12), dpi=500)plt.plot(train_fpr, train_tpr, color='red', lw=lw, label='Scikit learn Model 2 with intercept Train ROC curve')plt.subplots(figsize=(10, 4))plt.figure(figsize=(5, 5))plt.xlabel('Standard Deviations Used for Integral Band Width')plt.plot(max_features, test_results, 'r', label='Test AUC')plt.scatter(X_1[:, 0], X_1[:, 1], c=y_1, s=25)plt.legend(loc='upper left', bbox_to_anchor=[0, 1], ncol=2, fancybox=True)plt.plot(x, y, '.b')plt.subplots(4, 2, figsize=(15, 15))plt.ylabel('AUC score')plt.title('Box plot of all columns in dataset')plt.ylabel('Prices')plt.scatter(list(range(10, 95)), training_precision, label='training_precision')plt.title('Two Seperable Blobs')plt.subplot(224)plt.scatter(y[:, 0], y[:, 1], color='yellow')plt.title('Actual vs. predicted values')plt.yticks(np.arange(n_features), data_train.columns.values)plt.title('Four Blobs with Varying Separability')plt.scatter(X_21, X_22, c=y_2)plt.scatter(X1, X2, c=y, edgecolors='k')plt.subplot(222)plt.grid(False)plt.xlabel('x', fontsize=14)plt.scatter(x[:, 0], x[:, 1], color='purple')plt.title('Four blobs')plt.plot([d1_min, d1_max], [d2_at_mind1, d2_at_maxd1], color='black')plt.figure(figsize=(10, 10))plt.ylabel('y', fontsize=14)plt.hlines(y=y_val, xmin=x_value, xmax=x_value + delta_x, color='lightgreen', label=hline_lab)plt.ylabel('Gross Domestic Sales', fontsize=16)plt.barh(range(n_features), model.feature_importances_, align='center')plt.figure(figsize=(12, 14))plt.scatter(list(range(10, 95)), testing_precision, label='testing_precision')plt.subplot(121)plt.scatter(list(range(10, 95)), testing_accuracy, label='testing_accuracy')plt.scatter(x, 1.575 * x, label='Mean Ratio Model')plt.plot(fpr, tpr, color=colors[n], lw=lw, label='ROC curve Regularization Weight: {}'.format(names[n]))plt.xlabel('Resting Blood Pressure')plt.xlabel('Tree depth')plt.title('Two blobs')plt.xlabel('Budget', fontsize=16)plt.plot(max_features, train_results, 'b', label='Train AUC')plt.subplots(1, 2, figsize=(10, 5), sharey=True)plt.plot(x_values, function_values, label='f (x) = 3x^2\N{MINUS SIGN}11 ')plt.scatter(X_3[:, 0], X_3[:, 1], c=y_3, edgecolors='gray')plt.contourf(X1_C, X2_C, Z, alpha=1)plt.ylabel('Number of combinations for permutation test')plt.boxplot([df[col] for col in df.columns])plt.subplot(223)plt.subplots(figsize=(12, 6))plt.scatter(df['budget'], df['domgross'], label='Actual Data Points')plt.axis('tight')plt.title('d= %r, gam= %r, r = %r , score = %r' % (d, gamma, r, round(clf.score(X_train, y_train), 2)))plt.plot(test_fpr, test_tpr, color='darkorange', lw=lw, label='Test ROC curve')plt.xlabel('False Positive Rate')plt.scatter(y_test, poly_test_predictions, label='Model')plt.ylabel('Probability Density')plt.figure(figsize=(10, 4))plt.scatter(list(range(10, 95)), training_accuracy, label='training_accuracy')plt.subplots()plt.ylim([0.0, 1.05])plt.xticks(range(len(df.columns.values)), df.columns.values)plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve')plt.xlabel('Min. Sample Leafs')plt.title('Train and Test Accruaccy Versus Various Standard Deviation Bin Ranges for GNB')plt.ylabel('True Positive Rate')plt.subplots(nrows=1, ncols=1, figsize=(12, 12), dpi=300, tight_layout=True)plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')plt.title('LinearSVC')plt.figure(figsize=(10, 8))plt.plot(min_samples_splits, train_results, 'b', label='Train AUC')plt.xlabel('Min. Sample splits')plt.plot(range_stds, test_accs, label='Test Accuracy')plt.subplots(figsize=(10, 7))plt.legend()plt.tight_layout()plt.title('Four blobs with Varying Separability')plt.title('gam= %r, C= %r, score = %r' % (gamma, C, round(clf.score(X_4, y_4), 2)))plt.title('Receiver operating characteristic (ROC) Curve')#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# numpy as np#----------------------------------------------------------------------------------------------------np.arange(2, 11)np.linspace(start=df['budget'].min(), stop=df['budget'].max(), num=10 ** 5)np.meshgrid(x22_coord, x21_coord)np.linspace(-30, 30, 100)x_dev = np.linspace(x_value - line_length / 2, x_value + line_length / 2, 50)tree.plot_tree(clf, feature_names=df.columns, class_names=np.unique(y).astype('str'), filled=True)np.savetxt(sys.stdout, bval_rss, '%16.2f')np.floor(np.min([x[:, 1], y[:, 1]]))np.abs(y_test - y_hat_test)np.log(ames_cont)np.zeros((SIZE, SIZE))np.linalg.inv(XtX)tree.plot_tree(classifier_2, feature_names=X.columns, class_names=np.unique(y).astype('str'), filled=True, rounded=True)der_array = np.zeros(np.shape(function_terms))np.shape(X_train_scaled)table = np.zeros((len(b_values), 2))np.random.rand(100, 1).reshape(100)np.mean([yi ** 2 for yi in y_hat])np.array([[5, 30], [22, 2]])np.shape(array_of_terms)np.array([[4], [3]])np.random.seed(42)np.linspace(xi_lower, xi_upper)np.sqrt(rss(m))np.transpose(x)np.array(err)np.random.seed(11)np.zeros(len(m_current))initial_weights = np.ones((X.shape[1], 1)).flatten()np.array([1, 3])np.array([0.01, 1, 10])np.random.normal(0, 3, 30)np.arange(0, 14.5, step=0.5)np.array([constant, exponent])np.array([[5, 3], [2, 2]])np.array(err).mean()np.matrix([[12, 3], [8, 3]])np.dot(X, weights)np.mean(ai)np.mean(b)int(np.shape(function_terms)[0])np.array([0.1, 2])np.array([0.1, 1])np.ones((X.shape[1], 1)).flatten()np.transpose(data)np.matrix([[1, 1, 1], [0.1, 0.2, 0.3], [2, 0, -1]])np.abs(y_train - y_hat_train)np.sqrt(mean_sq_err)random_number = np.random.random()np.zeros((4, 4))np.transpose(A)np.arange(data.shape[0])np.linspace(0.1, 2, num=21)np.array([[2, 13], [1, 4], [72, 6], [18, 12], [27, 5]])x_survey_region = np.linspace(start=cur_x - previous_step_size, stop=cur_x + previous_step_size, num=101)predictions = sigmoid(np.dot(X, weights))np.abs(np.array(a) - np.array(b))np.array(a)FunctionTransformer(np.log, validate=True)np.transpose(x).dot(y)np.shape(function_terms)np.transpose(y)np.linspace(-10, 10, 100)np.isin(all_idx, training_idx)np.array([[2, 3], [6, 5]])np.argmax(c_probs)np.concatenate([X_test_cont, X_test_cat.todense()], axis=1)np.array([y, x])np.linspace(b - 1, b + 1, 100)np.mean(y_hat - y)np.matrix([[490, 448]])d1_min = np.min([x[:, 0], y[:, 0]])np.dot(X_train, weights)np.array([[4, 2], [4, 1], [-10, 0]])np.array([[3], [5], [9]])np.linalg.solve(A, B.T)np.unique(y)np.linspace(X1_min, X1_max, 500)np.bincount(labels)np.linspace(0, 200, num=50)int(np.shape(array_of_terms)[0])np.array([4, 2, 3])np.power(np.abs(np.array(a) - np.array(b)), c)train_mses.append(np.mean(inner_train_mses))np.array([[3, 2], [-11, 0]])np.mean(dt_grid_search.cv_results_['mean_train_score'])np.min([x[:, 1], y[:, 1]])term_output(np.array([3, 2]), 2)np.argmax(counts)m_gradient = np.zeros(len(m_current))diff_mu_ai_bi = np.mean(ai) - np.mean(bi)np.array([3, 2])np.array(x)np.random.seed(0)np.array([0.1, 1, 10])np.transpose(B)test_mses.append(np.mean(inner_test_mses))np.array([0.1, 1, 100])np.random.choice(self.population)np.matrix([162, 122])np.array([[5], [2]])np.shape(X_train_poly)np.concatenate([X_train_cont, X_train_cat.todense()], axis=1)np.round(y_hat_test, 2)np.array(b)np.array([[2, 3], [1, 4], [7, 6]])plt.ylim([np.floor(np.min([x[:, 1], y[:, 1]])), np.ceil(np.max([x[:, 1], y[:, 1]]))])np.mean(cross_val_score(rf_clf, X_train, y_train, cv=3))np.linspace(start=cur_x - previous_step_size, stop=cur_x + previous_step_size, num=101)np.random.rand(30, 1).reshape(30)np.array(data)np.gradient(rss_survey_region)np.matrix([[29, 41], [23, 41]])np.array([[1402, 191], [1371, 821], [949, 1437], [147, 1448]])np.transpose(A.dot(B))np.linspace(0.1, 0.5, 5, endpoint=True)np.array([0.001, 0.01, 0.1])np.random.seed(225)np.dot(Xt, y_train)np.array([[4, 3], [11, 2]])d1_max = np.max([x[:, 0], y[:, 0]])np.linspace(X12_min, X12_max, 10)np.linspace(X2_min, X2_max, 500)np.matrix([[7, 5.25, 0]])np.argmax(posteriors)np.log(num / denom)counts = np.bincount(labels)np.array([3, 4])np.linspace(start=-3, stop=5, num=10 ** 3)np.linspace(0.1, 1.0, 10, endpoint=True)np.linspace(X21_min, X21_max, 10)print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))np.random.random()p = np.log(p_classes[class_])np.unique(y).astype('str')np.linspace(X11_min, X11_max, 10)gradient = np.gradient(rss_survey_region)[50]np.power(np.sum(np.power(np.abs(np.array(a) - np.array(b)), c)), 1 / c)np.matrix([[1240, 276, 0]])np.max([x[:, 1], y[:, 1]])np.linalg.inv(A)plt.yticks(np.arange(n_features), data_train.columns.values)np.matrix([[1, 1, 1], [0.5, 0.75, 1.25], [-2, 1, 0]])np.set_printoptions(formatter={'float_kind': '{:f}'.format})np.mean(dt_cv_score)np.sum(np.power(np.abs(np.array(a) - np.array(b)), c))np.meshgrid(x12_coord, x11_coord)np.dot(Xt, x_train)np.array([[4, 3], [-3, 1]])np.array([[4, 1], [15, 0]])np.linspace(X22_min, X22_max, 10)np.argmin(test_mse)np.random.normal(0, 0.2, 100)range(int(np.shape(array_of_terms)[0]))np.mean(test_residuals.astype(float) ** 2)ai = np.random.choice(union, size=len(a), replace=False)np.mean(inner_train_mses)sigmoid(np.dot(X_train, weights))np.ones((X.shape[1], 1))np.array([y, x1, x2])np.linspace(temp.min(), temp.max(), num=10 ** 3)np.array([2, 2])np.shape(x11x12)np.transpose(x_train)gradient = np.dot(X.transpose(), error_vector)np.mean(y_hat)test_errs.append(np.mean(test_residuals.astype(float) ** 2))np.array([[1, 2, 3], [4, 5, 6]])np.random.choice(union, size=len(a), replace=False)np.mean(inner_test_mses)np.shape(array_1)sigmoid(np.dot(X, weights))np.meshgrid(x2_coord, x1_coord)np.dot(X_test, weights)sigmoid(np.dot(X_test, weights))np.mean(a)np.random.rand(30, 1)np.max([x[:, 0], y[:, 0]])np.dot(X.transpose(), error_vector)np.sqrt(mean_squared_error(y_test, y_pred))np.linspace(X2_min, X2_max, 200)np.random.rand(SIZE, SIZE)np.random.choice(all_idx, size=round(546 * 0.8), replace=False)x_values = [np.linspace(b - 1, b + 1, 100) for b in b_vals]np.log(p_classes[class_])np.zeros((3, 3))np.ceil(np.max([x[:, 1], y[:, 1]]))np.min([x[:, 0], y[:, 0]])np.mean(bi)x = np.array(x)np.linspace(x_value - line_length / 2, x_value + line_length / 2, 50)np.arange(n_features)np.transpose(y).dot(x)rss_survey_region = [np.sqrt(rss(m)) for m in x_survey_region]np.linspace(0.5, 0.9, 10)range(int(np.shape(function_terms)[0]))np.linspace(X1_min, X1_max, 200)np.zeros(np.shape(function_terms))np.random.rand(100, 1)np.transpose(B).dot(np.transpose(A))np.linspace(0, 5, 100)random_person = np.random.choice(self.population)np.array([[2], [6], [7]])np.zeros((len(b_values), 2))np.array([x, y])#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# ride as ride#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# Ride as Ride#----------------------------------------------------------------------------------------------------Ride()#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# Driver as Driver#----------------------------------------------------------------------------------------------------Driver()#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# load_iris as load_iris#----------------------------------------------------------------------------------------------------load_iris()load_iris(return_X_y=True, as_frame=True)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# MinMaxScaler as MinMaxScaler#----------------------------------------------------------------------------------------------------MinMaxScaler()#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# DecisionTreeClassifier as DecisionTreeClassifier#----------------------------------------------------------------------------------------------------dt = DecisionTreeClassifier(criterion='entropy', max_features=max_feature, random_state=SEED)BaggingClassifier(DecisionTreeClassifier(criterion='gini', max_depth=5), n_estimators=20)dt = DecisionTreeClassifier(criterion='entropy', max_depth=max_depth, random_state=SEED)DecisionTreeClassifier(random_state=10, criterion='entropy')DecisionTreeClassifier(criterion='entropy')DecisionTreeClassifier()dt = DecisionTreeClassifier(criterion='entropy', min_samples_split=min_samples_split, random_state=SEED)DecisionTreeClassifier(criterion='entropy', max_features=6, max_depth=3, min_samples_split=0.7, min_samples_leaf=0.25, random_state=SEED)dt = DecisionTreeClassifier(criterion='entropy', min_samples_leaf=min_samples_leaf, random_state=SEED)DecisionTreeClassifier(criterion='entropy', min_samples_leaf=min_samples_leaf, random_state=SEED)DecisionTreeClassifier(random_state=10)DecisionTreeClassifier(criterion='entropy', max_features=max_feature, random_state=SEED)DecisionTreeClassifier(criterion='gini', max_depth=5)DecisionTreeClassifier(criterion='entropy', max_depth=max_depth, random_state=SEED)DecisionTreeClassifier(criterion='entropy', min_samples_split=min_samples_split, random_state=SEED)DecisionTreeClassifier(criterion='entropy', random_state=SEED)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# csv as csv#----------------------------------------------------------------------------------------------------raw = csv.reader(f)csv.reader(f)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# rcParams as rcParams#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# sys as sys#----------------------------------------------------------------------------------------------------np.savetxt(sys.stdout, bval_rss, '%16.2f')#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# pandas as pd#----------------------------------------------------------------------------------------------------pd.concat([X_test.drop(col, axis=1), col_transformed_test], axis=1)pd.DataFrame()pd.Series(residuals).value_counts()print(pd.Series(y_resampled).value_counts())X_val = pd.concat([X_val.drop(col, axis=1), col_transformed_val], axis=1)pd.read_csv('heart.csv')col_transformed_test = pd.DataFrame(poly.transform(features_test[[col]]))pd.read_csv('pima-indians-diabetes.csv')pd.DataFrame(poly.fit_transform(X_val[[col]]), columns=poly.get_feature_names([col]))pd.concat([features_train.drop(col, axis=1), col_transformed_train], axis=1)pd.concat([y_train, y_test])pd.Series(residuals).value_counts(normalize=True)print(pd.Series(residuals).value_counts())X_train = pd.concat([pd.DataFrame(log_transformer.transform(X_train[continuous]), index=X_train.index), pd.DataFrame(ohe.transform(X_train[categoricals]), index=X_train.index)], axis=1)pd.concat([X_val.drop(col, axis=1), col_transformed_val], axis=1)pd.DataFrame(poly.transform(X_test[[col]]), columns=poly.get_feature_names([col]))pd.concat([pd.DataFrame(log_transformer.transform(X_train[continuous]), index=X_train.index), pd.DataFrame(ohe.transform(X_train[categoricals]), index=X_train.index)], axis=1)pd.Series(y_resampled)print(pd.Series(y_train_resampled).value_counts())pd.concat([X_train, y_train], axis=1)pd.concat([X_train, X_test])pd.DataFrame(top_7_polynomials, columns=['Column', 'Degree', 'R^2'])pd.read_csv('mushrooms.csv')col_transformed_train = pd.DataFrame(poly.fit_transform(X_train[[col]]), columns=poly.get_feature_names([col]))features_test = pd.concat([features_test.drop(col, axis=1), col_transformed_test], axis=1)pd.get_dummies(salaries)pd.get_dummies(df[relevant_columns], drop_first=True, dtype=float)pd.get_dummies(salaries['Target'], drop_first=True)X_test = pd.concat([pd.DataFrame(log_transformer.transform(X_test[continuous]), index=X_test.index), pd.DataFrame(ohe.transform(X_test[categoricals]), index=X_test.index)], axis=1)pd.DataFrame(X_val_scaled, columns=X.columns)pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)pd.DataFrame(ohe.transform(X_test[categoricals]), index=X_test.index)final_model.fit(pd.concat([X_train, X_test]), pd.concat([y_train, y_test]))X_train = pd.concat([fold for (i, fold) in enumerate(X_folds) if i != n])pd.concat([X_train.drop(col, axis=1), col_transformed_train], axis=1)pd.read_csv('SMSSpamCollection', sep='\t', names=['label', 'text'])pd.DataFrame(poly.fit_transform(X_train[[col]]), columns=poly.get_feature_names([col]))pd.Series(y_train_resampled)pd.crosstab(y_test, y_preds, rownames=['True'], colnames=['Predicted'], margins=True)self.time_step_statistics_df = pd.DataFrame()pd.Series(encoder.fit_transform(y_train))pd.concat([ames_log_norm, ames_ohe], axis=1)pd.read_csv('housing_prices.csv', index_col=0)pd.DataFrame({'color': ['red', 'orange', 'yellow', 'green', 'blue', 'indigo', 'violet']})pd.read_csv('./mushrooms.csv')y_train = pd.concat([fold for (i, fold) in enumerate(y_folds) if i != n])col_transformed_val = pd.DataFrame(poly.fit_transform(X_val[[col]]), columns=poly.get_feature_names([col]))pd.get_dummies(X, drop_first=True)pd.read_csv('ames.csv', index_col=0)pd.DataFrame(poly.fit_transform(features_train[[col]]))pd.Series(y_resampled).value_counts()pd.DataFrame(initial_weights)pd.DataFrame(X_test_scaled, columns=X.columns)pd.Series(y_train_resampled).value_counts()pd.read_csv('winequality-red.csv')pd.read_excel('movie_data_detailed_with_ols.xlsx')pd.concat([weights_col, pd.DataFrame(weights)], axis=1)pd.concat([minority, undersampled_majority])X_train = pd.concat([X_train.drop(col, axis=1), col_transformed_train], axis=1)pd.DataFrame(ohe.transform(X_train[categoricals]), index=X_train.index)pd.DataFrame(log_transformer.transform(X_test[continuous]), index=X_test.index)pd.read_csv('ames.csv')pd.plotting.scatter_matrix(df, figsize=(10, 10))pd.concat([X_test, y_test], axis=1)pd.DataFrame(log_transformer.transform(X_train[continuous]), index=X_train.index)pd.DataFrame(scaled_data_train, columns=one_hot_df.columns)pd.read_csv('./data_banknote_authentication.csv', header=None, names=['Variance', 'Skewness', 'Kurtosis', 'Entropy'])weights_col = pd.DataFrame(initial_weights)pd.read_csv('data_banknote_authentication.csv', header=None)pd.DataFrame(X_train_scaled, columns=X.columns)pd.read_csv('creditcard.csv.gz', compression='gzip')pd.get_dummies(df['class'], drop_first=True)pd.read_csv('simulation.csv')pd.DataFrame(poly.transform(features_test[[col]]))features_train = pd.concat([features_train.drop(col, axis=1), col_transformed_train], axis=1)pd.concat([pd.DataFrame(log_transformer.transform(X_test[continuous]), index=X_test.index), pd.DataFrame(ohe.transform(X_test[categoricals]), index=X_test.index)], axis=1)X_test = pd.concat([X_test.drop(col, axis=1), col_transformed_test], axis=1)pd.read_csv('titanic.csv')pd.concat([fold for (i, fold) in enumerate(X_folds) if i != n])pd.read_excel('movie_data.xlsx')pd.concat([fold for (i, fold) in enumerate(y_folds) if i != n])pd.read_csv('petrol_consumption.csv')pd.Series(residuals)weights_col = pd.concat([weights_col, pd.DataFrame(weights)], axis=1)pd.get_dummies(df)col_transformed_train = pd.DataFrame(poly.fit_transform(features_train[[col]]))pd.DataFrame(weights)pd.Series(encoder.transform(y_test))col_transformed_test = pd.DataFrame(poly.transform(X_test[[col]]), columns=poly.get_feature_names([col]))print(pd.Series(residuals).value_counts(normalize=True))pd.read_csv('salaries_final.csv', index_col=0)pd.get_dummies(salaries[xcols], drop_first=True)pd.get_dummies(ames[categoricals], prefix=categoricals, drop_first=True)pd.concat([features_test.drop(col, axis=1), col_transformed_test], axis=1)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# FunctionTransformer as FunctionTransformer#----------------------------------------------------------------------------------------------------FunctionTransformer(np.log, validate=True)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# OneHotEncoder as OneHotEncoder#----------------------------------------------------------------------------------------------------OneHotEncoder(drop='first', sparse=False)OneHotEncoder(handle_unknown='ignore')#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# train_test_split as train_test_split#----------------------------------------------------------------------------------------------------train_test_split(X, y, random_state=1)(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=t_size, random_state=i)(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=None)train_test_split(X, y, test_size=i / 100.0)(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=i / 100.0)train_test_split(X, y, test_size=0.3, random_state=SEED)train_test_split(one_hot_df, labels, test_size=0.25, random_state=42)train_test_split(X, y, random_state=17)train_test_split(X, y, test_size=0.2, random_state=4)train_test_split(X, y, test_size=t_size, random_state=42)train_test_split(X_3, y_3, test_size=0.33, random_state=123)train_test_split(data, target, test_size=0.25, random_state=123)train_test_split(X, y, test_size=0.2, random_state=42)train_test_split(X, y, random_state=42)train_test_split(X, y, test_size=None)train_test_split(X, y, test_size=0.2, random_state=10)(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=t_size, random_state=42)train_test_split(data, target, test_size=0.25, random_state=0)train_test_split(X, y, test_size=0.25, random_state=42)train_test_split(X_train, y_train, random_state=0)train_test_split(X, y, random_state=0)train_test_split(X, y, random_state=10)train_test_split(df, target, test_size=0.25, random_state=42)train_test_split(X_resampled, y_resampled, random_state=0)train_test_split(features, target, test_size=0.2, random_state=42)train_test_split(X, y, test_size=0.25, random_state=22)train_test_split(X, y, test_size=t_size, random_state=i)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# LinearRegression as LinearRegression#----------------------------------------------------------------------------------------------------LinearRegression().fit(features_train, y_train).score(features_test, y_test)LinearRegression().fit(features_train, y_train)RFE(LinearRegression(), n_features_to_select=n)rfe = RFE(LinearRegression(), n_features_to_select=n)LinearRegression()score = LinearRegression().fit(features_train, y_train).score(features_test, y_test)lr = LinearRegression()#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# mean_squared_error as mean_squared_error#----------------------------------------------------------------------------------------------------print('Lasso, alpha=1:   ', mean_squared_error(y_test, lasso.predict(X_test_preprocessed)))mean_squared_error(y_test, lasso_10.predict(X_test_preprocessed))mean_squared_error(y_test, linreg.predict(X_test_preprocessed))print('Test MSE:    ', mean_squared_error(y_test, ridge.predict(X_test_preprocessed)))print('Test MSE:    ', mean_squared_error(y_test, lasso_10.predict(X_test_preprocessed)))print('MSE:', mean_squared_error(y_val, final_model.predict(X_val)))print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train_preprocessed)))print('Training MSE:', mean_squared_error(y_train, lasso_10.predict(X_train_preprocessed)))mean_squared_error(y_test, ridge_10.predict(X_test_preprocessed))mean_squared_error(y_test, lasso.predict(X_test_preprocessed))print('Test MSE:    ', mean_squared_error(y_test, linreg.predict(X_test_preprocessed)))print('Training MSE:', mean_squared_error(y_train, linreg.predict(X_train_preprocessed)))mean_squared_error(y_test, test_preds)mean_squared_error(y_val, final_model.predict(X_val))print('Ridge, alpha=10:  ', mean_squared_error(y_test, ridge_10.predict(X_test_preprocessed)))mean_squared_error(y_true, y_predict, squared=False)print('Mean Squared Error:', mean_squared_error(y_test, y_pred))print('Test MSE:    ', mean_squared_error(y_test, ridge_10.predict(X_test_preprocessed)))print('Linear Regression:', mean_squared_error(y_test, linreg.predict(X_test_preprocessed)))test_mse.append(mean_squared_error(y_test, test_preds))mean_squared_error(y_train, linreg.predict(X_train_preprocessed))mean_squared_error(y_train, y_hat_train)mean_squared_error(y_train, lasso_10.predict(X_train_preprocessed))mean_squared_error(y_train, ridge.predict(X_train_preprocessed))np.sqrt(mean_squared_error(y_test, y_pred))inner_test_mses.append(mean_squared_error(y_test, y_hat_test))print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))inner_train_mses.append(mean_squared_error(y_train, y_hat_train))mean_squared_error(y_test, ridge.predict(X_test_preprocessed))print('Training MSE:', mean_squared_error(y_train, ridge.predict(X_train_preprocessed)))mean_squared_error(y_test, y_hat_test)mean_squared_error(y_test, y_pred)print('Training MSE:', mean_squared_error(y_train, ridge_10.predict(X_train_preprocessed)))mean_squared_error(y_train, train_preds)train_mses.append(mean_squared_error(y_train, y_hat_train))print('Ridge, alpha=1:   ', mean_squared_error(y_test, ridge.predict(X_test_preprocessed)))mean_squared_error(y_train, lasso.predict(X_train_preprocessed))rmse = mean_squared_error(y_true, y_predict, squared=False)print('Lasso, alpha=10:  ', mean_squared_error(y_test, lasso_10.predict(X_test_preprocessed)))mean_squared_error(y_train, ridge_10.predict(X_train_preprocessed))print('Test MSE:    ', mean_squared_error(y_test, lasso.predict(X_test_preprocessed)))train_mse.append(mean_squared_error(y_train, train_preds))test_mses.append(mean_squared_error(y_test, y_hat_test))#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# cross_val_score as cross_val_score#----------------------------------------------------------------------------------------------------cross_val_score(gbt_clf, df, target, cv=5)cross_val_score(linreg, X, y, cv=5, scoring='neg_mean_squared_error')cross_val_score(rf_clf, X_train, y_train, cv=3)np.mean(cross_val_score(rf_clf, X_train, y_train, cv=3))cross_val_score(gbt_clf, df, target, cv=5).mean()print(cross_val_score(gbt_clf, df, target, cv=5).mean())cross_val_score(adaboost_clf, df, target, cv=5)cross_val_score(adaboost_clf, df, target, cv=5).mean()print(cross_val_score(adaboost_clf, df, target, cv=5).mean())cross_val_score(dt_clf, X_train, y_train, cv=3)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# PolynomialFeatures as PolynomialFeatures#----------------------------------------------------------------------------------------------------PolynomialFeatures(3)poly = PolynomialFeatures(degree, include_bias=False)PolynomialFeatures(degree, include_bias=False)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# * as *#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# warnings as warnings#----------------------------------------------------------------------------------------------------warnings.filterwarnings('ignore')#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# SimpleImputer as SimpleImputer#----------------------------------------------------------------------------------------------------SimpleImputer(strategy='median')SimpleImputer(strategy='constant', fill_value='missing')#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# Lasso as Lasso#----------------------------------------------------------------------------------------------------Lasso(alpha=1)Lasso()Lasso(alpha=10000)Lasso(alpha=alpha)lasso = Lasso(alpha=alpha)Lasso(alpha=10)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# Ridge as Ridge#----------------------------------------------------------------------------------------------------Ridge()Ridge(alpha=10)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# combinations as combinations#----------------------------------------------------------------------------------------------------list(combinations(X_train.columns, 2))combinations(X_train.columns, 2)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# RFE as RFE#----------------------------------------------------------------------------------------------------RFE(LinearRegression(), n_features_to_select=n)rfe = RFE(LinearRegression(), n_features_to_select=n)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# StandardScaler as StandardScaler#----------------------------------------------------------------------------------------------------StandardScaler()#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# statsmodels.api as sm#----------------------------------------------------------------------------------------------------sm.tools.add_constant(X)sm.Logit(y, X)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# LogisticRegression as LogisticRegression#----------------------------------------------------------------------------------------------------LogisticRegression(fit_intercept=False, solver='liblinear')LogisticRegression(fit_intercept=False, C=1e+16, solver='liblinear')LogisticRegression(fit_intercept=False, C=1e+20, solver='liblinear')LogisticRegression(fit_intercept=False, C=1e+25, solver='liblinear')LogisticRegression(fit_intercept=False, C=c, solver='liblinear')logreg = LogisticRegression(fit_intercept=True, C=1.5 ** n, solver='liblinear')logreg = LogisticRegression(fit_intercept=False, C=1e+20, solver='liblinear')LogisticRegression(fit_intercept=True, C=1e+16, solver='liblinear')LogisticRegression(fit_intercept=True, C=1.5 ** n, solver='liblinear')LogisticRegression(fit_intercept=False, C=1000000000000.0, solver='liblinear')logreg = LogisticRegression(fit_intercept=False, C=1e+25, solver='liblinear')LogisticRegression(C=1000000000000.0, fit_intercept=False, solver='liblinear')logreg = LogisticRegression(fit_intercept=False, C=c, solver='liblinear')#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# confusion_matrix as confusion_matrix#----------------------------------------------------------------------------------------------------confusion_matrix(test_predictions, y_test)confusion_matrix(target_test, pred)confusion_matrix(y_test, gbt_clf_test_preds)confusion_matrix(y_test, y_hat_test)print(confusion_matrix(target_test, pred))confusion_matrix(y_test, adaboost_test_preds)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# plot_confusion_matrix as plot_confusion_matrix#----------------------------------------------------------------------------------------------------plot_confusion_matrix(model_log, X_test, y_test)plot_confusion_matrix(logreg, X_test, y_test, display_labels=['not fraud', 'fraud'], values_format='.5g')plot_confusion_matrix(clf, X, y, values_format='.3g')plot_confusion_matrix(classifier, X, y, values_format='.3g')plot_confusion_matrix(logreg, X_test, y_test, cmap=plt.cm.Blues)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# precision_score as precision_score#----------------------------------------------------------------------------------------------------precision_score(y_train, y_hat_train)print('Testing Precision: ', precision_score(y_test, y_hat_test))precision_score(labels, preds)precision_score(y_test, y_hat_test)'Precision Score: {}'.format(precision_score(labels, preds))print('Training Precision: ', precision_score(y_train, y_hat_train))print('Precision Score: {}'.format(precision_score(labels, preds)))#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# recall_score as recall_score#----------------------------------------------------------------------------------------------------print('Recall Score: {}'.format(recall_score(labels, preds)))recall_score(y_test, y_hat_test)recall_score(y_train, y_hat_train)recall_score(labels, preds)print('Training Recall: ', recall_score(y_train, y_hat_train))'Recall Score: {}'.format(recall_score(labels, preds))print('Testing Recall: ', recall_score(y_test, y_hat_test))#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# accuracy_score as accuracy_score#----------------------------------------------------------------------------------------------------accuracy_score(y_test, y_preds)print('Accuracy Score: {}'.format(accuracy_score(labels, preds)))accuracy_score(y_train, training_preds)acc = accuracy_score(true, preds)print('Testing Accuracy for Decision Tree Classifier: {:.4}%'.format(accuracy_score(target_test, pred) * 100))print('Training Accuracy: ', accuracy_score(y_train, y_hat_train))accuracy_score(true, preds)'Testing Accuracy: {}'.format(accuracy_score(y_test, preds))accuracy_score(labels, preds)accuracy_score(y_test, y_hat_test)print('Testing Accuracy: ', accuracy_score(y_test, y_hat_test))'Testing Accuracy for Decision Tree Classifier: {:.4}%'.format(accuracy_score(target_test, pred) * 100)accuracy_score(y_train, y_hat_train)accuracy_score(y_test, preds)print('Testing Accuracy: {}'.format(accuracy_score(y_test, preds)))'Accuracy Score: {}'.format(accuracy_score(labels, preds))accuracy_score(y_test, y_pred)accuracy_score(y_test, test_preds)accuracy_score(target_test, pred)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# f1_score as f1_score#----------------------------------------------------------------------------------------------------print('Training F1-Score: ', f1_score(y_train, y_hat_train))f1_score(labels, preds)f1_score(y_test, preds)'F1 Score: {}'.format(f1_score(labels, preds))f1_score(y_train, y_hat_train)print('Testing F1-Score: ', f1_score(y_test, y_hat_test))f1 = f1_score(true, preds)f1_score(y_test, y_hat_test)f1 = f1_score(y_test, preds)print('F1 Score: {}'.format(f1_score(labels, preds)))f1_score(true, preds)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# roc_curve as roc_curve#----------------------------------------------------------------------------------------------------(false_positive_rate, true_positive_rate, thresholds) = roc_curve(y_train, train_pred)roc_curve(y_test, y_score)roc_curve(y_train, y_hat_train)roc_curve(y_test, y_pred)roc_curve(y_test, y_hat_test)roc_curve(y_train, y_train_score)roc_curve(y_train, train_pred)(false_positive_rate, true_positive_rate, thresholds) = roc_curve(y_test, y_pred)(test_fpr, test_tpr, test_thresholds) = roc_curve(y_test, y_test_score)(fpr, tpr, thresholds) = roc_curve(y_test, y_score)(train_fpr, train_tpr, train_thresholds) = roc_curve(y_train, y_train_score)roc_curve(y_test, y_test_score)roc_curve(y_test, y_preds)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# auc as auc#----------------------------------------------------------------------------------------------------'Scikit-learn Model 2 with intercept Test AUC: {}'.format(auc(test_fpr, test_tpr))'AUC for {}: {}'.format(names[n], auc(fpr, tpr))auc(train_fpr, train_tpr)print('Scikit-learn Model 1 Test AUC: {}'.format(auc(test_fpr, test_tpr)))print('AUC for {}: {}'.format(names[n], auc(fpr, tpr)))auc(test_fpr, test_tpr)print('Custom Model Test AUC: {}'.format(auc(test_fpr, test_tpr)))print('AUC: {}'.format(auc(fpr, tpr)))auc(false_positive_rate, true_positive_rate)roc_auc = auc(false_positive_rate, true_positive_rate)print('AUC: {}'.format(auc(train_fpr, train_tpr)))'Scikit-learn Model 2 with intercept Train AUC: {}'.format(auc(train_fpr, train_tpr))train_auc = auc(train_fpr, train_tpr)'Scikit-learn Model 1 Train AUC: {}'.format(auc(train_fpr, train_tpr))'Custome Model Train AUC: {}'.format(auc(train_fpr, train_tpr))'Custom Model Test AUC: {}'.format(auc(test_fpr, test_tpr))'AUC: {}'.format(auc(fpr, tpr))test_auc = auc(test_fpr, test_tpr)print('Train AUC: {}'.format(auc(train_fpr, train_tpr)))'Scikit-learn Model 1 Test AUC: {}'.format(auc(test_fpr, test_tpr))print('Scikit-learn Model 2 with intercept Test AUC: {}'.format(auc(test_fpr, test_tpr)))'AUC: {}'.format(auc(test_fpr, test_tpr))'Training AUC: {}'.format(auc(train_fpr, train_tpr))'AUC: {}'.format(auc(train_fpr, train_tpr))print('Custome Model Train AUC: {}'.format(auc(train_fpr, train_tpr)))'Test AUC: {}'.format(auc(test_fpr, test_tpr))print('Test AUC: {}'.format(auc(test_fpr, test_tpr)))print('Training AUC: {}'.format(auc(train_fpr, train_tpr)))auc(fpr, tpr)print('Scikit-learn Model 2 with intercept Train AUC: {}'.format(auc(train_fpr, train_tpr)))print('AUC: {}'.format(auc(test_fpr, test_tpr)))print('Scikit-learn Model 1 Train AUC: {}'.format(auc(train_fpr, train_tpr)))'Train AUC: {}'.format(auc(train_fpr, train_tpr))#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# seaborn as sns#----------------------------------------------------------------------------------------------------sns.set_style('white')sns.color_palette('Set2')sns.color_palette('Set2', n_colors=len(names))sns.set_style('darkgrid', {'axes.facecolor': '0.9'})#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# itertools as itertools#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# SMOTE as SMOTE#----------------------------------------------------------------------------------------------------SMOTE().fit_sample(X, y)SMOTE().fit_resample(X_train, y_train)SMOTE()SMOTE().fit_resample(X, y)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# ADASYN as ADASYN#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# log as log#----------------------------------------------------------------------------------------------------log(p, 2)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# tree as tree#----------------------------------------------------------------------------------------------------tree.plot_tree(clf, feature_names=df.columns, class_names=np.unique(y).astype('str'), filled=True)tree.plot_tree(classifier_2, feature_names=X.columns, class_names=np.unique(y).astype('str'), filled=True, rounded=True)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# tabulate as tabulate#----------------------------------------------------------------------------------------------------print(tabulate([['Entropy']], tablefmt='fancy_grid'))tabulate([['Entropy']], tablefmt='fancy_grid')tabulate(output, tablefmt='fancy_grid')print(tabulate(output, tablefmt='fancy_grid'))#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# matplotlib as mpl#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# mean_absolute_error as mean_absolute_error#----------------------------------------------------------------------------------------------------print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))mean_absolute_error(y_test, y_pred)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# DecisionTreeRegressor as DecisionTreeRegressor#----------------------------------------------------------------------------------------------------regressor = DecisionTreeRegressor(max_depth=max_depth, random_state=45)DecisionTreeRegressor(random_state=42)DecisionTreeRegressor(min_samples_split=int(min_samples_split), random_state=45)DecisionTreeRegressor(min_samples_split=5, max_depth=7, random_state=45)DecisionTreeRegressor(max_depth=max_depth, random_state=45)DecisionTreeRegressor(random_state=45)regressor = DecisionTreeRegressor(min_samples_split=int(min_samples_split), random_state=45)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# r2_score as r2_score#----------------------------------------------------------------------------------------------------r2_score(y_true, y_predict)r2 = r2_score(y_true, y_predict)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# euclidean as euclidean#----------------------------------------------------------------------------------------------------dist_to_i = euclidean(x, val)euclidean(x, val)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# KNeighborsClassifier as KNeighborsClassifier#----------------------------------------------------------------------------------------------------KNeighborsClassifier()KNeighborsClassifier(n_neighbors=k)knn = KNeighborsClassifier(n_neighbors=k)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# stats as stats#----------------------------------------------------------------------------------------------------stats.norm.cdf(interval_max, loc=mu, scale=std)stats.norm.pdf(145, loc=aggs['mean'], scale=aggs['std'])p_x_given_y = stats.norm.pdf(obs, loc=mu, scale=std)stats.norm.pdf(ix, loc=aggs['mean'], scale=aggs['std'])stats.norm.pdf(x, loc=aggs['mean'], scale=aggs['std'])cdf_min = stats.norm.cdf(interval_min, loc=mu, scale=std)stats.norm.pdf(obs, loc=mu, scale=std)stats.norm.cdf(xi_upper, loc=aggs['mean'], scale=aggs['std'])cdf_max = stats.norm.cdf(interval_max, loc=mu, scale=std)stats.norm.cdf(interval_min, loc=mu, scale=std)plt.plot((145, 145), (0, stats.norm.pdf(145, loc=aggs['mean'], scale=aggs['std'])), linestyle='dotted')stats.norm.cdf(xi_lower, loc=aggs['mean'], scale=aggs['std'])#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# Polygon as Polygon#----------------------------------------------------------------------------------------------------Polygon(verts, facecolor='0.9', edgecolor='0.5')#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# scipy.stats as stats#----------------------------------------------------------------------------------------------------stats.norm.cdf(interval_max, loc=mu, scale=std)stats.norm.pdf(145, loc=aggs['mean'], scale=aggs['std'])p_x_given_y = stats.norm.pdf(obs, loc=mu, scale=std)stats.norm.pdf(ix, loc=aggs['mean'], scale=aggs['std'])stats.norm.pdf(x, loc=aggs['mean'], scale=aggs['std'])cdf_min = stats.norm.cdf(interval_min, loc=mu, scale=std)stats.norm.pdf(obs, loc=mu, scale=std)stats.norm.cdf(xi_upper, loc=aggs['mean'], scale=aggs['std'])cdf_max = stats.norm.cdf(interval_max, loc=mu, scale=std)stats.norm.cdf(interval_min, loc=mu, scale=std)plt.plot((145, 145), (0, stats.norm.pdf(145, loc=aggs['mean'], scale=aggs['std'])), linestyle='dotted')stats.norm.cdf(xi_lower, loc=aggs['mean'], scale=aggs['std'])#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# classification_report as classification_report#----------------------------------------------------------------------------------------------------classification_report(target_test, pred)classification_report(y_test, adaboost_test_preds)print(classification_report(target_test, pred))classification_report(y_test, gbt_clf_test_preds)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# BaggingClassifier as BaggingClassifier#----------------------------------------------------------------------------------------------------BaggingClassifier(DecisionTreeClassifier(criterion='gini', max_depth=5), n_estimators=20)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# RandomForestClassifier as RandomForestClassifier#----------------------------------------------------------------------------------------------------RandomForestClassifier()RandomForestClassifier(n_estimators=100, max_depth=5)RandomForestClassifier(n_estimators=5, max_features=10, max_depth=2)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# GridSearchCV as GridSearchCV#----------------------------------------------------------------------------------------------------GridSearchCV(clf, param_grid, scoring='accuracy', cv=None, n_jobs=1)GridSearchCV(rf_clf, rf_param_grid, cv=3)GridSearchCV(dt_clf, dt_param_grid, cv=3, return_train_score=True)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# AdaBoostClassifier as AdaBoostClassifier#----------------------------------------------------------------------------------------------------AdaBoostClassifier(random_state=42)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# GradientBoostingClassifier as GradientBoostingClassifier#----------------------------------------------------------------------------------------------------GradientBoostingClassifier(random_state=42)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# XGBClassifier as XGBClassifier#----------------------------------------------------------------------------------------------------XGBClassifier()#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# LabelEncoder as LabelEncoder#----------------------------------------------------------------------------------------------------LabelEncoder()#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# School as School#----------------------------------------------------------------------------------------------------School('Middletown High School')#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# ShoppingCart as ShoppingCart#----------------------------------------------------------------------------------------------------ShoppingCart()ShoppingCart(20)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# tqdm as tqdm#----------------------------------------------------------------------------------------------------tqdm(range(self.total_time_steps))#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# random as random#----------------------------------------------------------------------------------------------------matrix[x][y] = random.randrange(1, 10)M[x][y] = random.randrange(1, 10)random.randrange(1, 10)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# timeit as timeit#----------------------------------------------------------------------------------------------------timeit.default_timer()#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# make_blobs as make_blobs#----------------------------------------------------------------------------------------------------make_blobs(n_features=2, centers=2, cluster_std=3, random_state=123)make_blobs(n_samples=100, n_features=2, centers=2, cluster_std=3, random_state=123)make_blobs(n_samples=100, n_features=2, centers=4, cluster_std=1.6, random_state=123)make_blobs(n_features=2, centers=2, cluster_std=1.25, random_state=123)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# cvxpy as cp#----------------------------------------------------------------------------------------------------cp.Minimize(cp.norm(w, 2))cp.Minimize(cp.norm(w, 2) + C * (sum(ksi_1) + sum(ksi_2)))cp.Problem(obj, constraints)cp.Variable(d)cp.Variable(m)cp.Variable()cp.Variable(n)cp.norm(w, 2)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# make_moons as make_moons#----------------------------------------------------------------------------------------------------make_moons(n_samples=100, shuffle=False, noise=0.3, random_state=123)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# svm as svm#----------------------------------------------------------------------------------------------------svm.SVC(C=C, gamma=gamma)svm.SVC(kernel='sigmoid', coef0=r, gamma=gamma)svm.SVC(kernel='poly', coef0=r, gamma=gamma, degree=d)svm.SVC(kernel='linear', C=0.1)svm.NuSVC(kernel='linear', nu=0.7)svm.LinearSVC()clf = svm.SVC(kernel='sigmoid', coef0=r, gamma=gamma)svm.SVC(probability=True)svm.SVC(kernel='linear', C=1)clf = svm.SVC(kernel='poly', coef0=r, gamma=gamma, degree=d)clf = svm.SVC(C=C, gamma=gamma)#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# SVC as SVC#----------------------------------------------------------------------------------------------------SVC(kernel='linear', C=5000000)SVC(kernel='linear')#----------------------------------------------------------------------------------------------------#----------------------------------------------------------------------------------------------------# statsmodels as sm#----------------------------------------------------------------------------------------------------sm.tools.add_constant(X)sm.Logit(y, X)#----------------------------------------------------------------------------------------------------